#!/bin/bash
# container-adoption-report.sh
# Show adoption of Chainguard Images
#
# Copyright (c) 2025 Chainguard, Inc.
# SPDX-License-Identifier: MIT

set -eu

# Restrictive permissions for new files
umask 022

# Config
SLEEP_TIME="${SLEEP_TIME:-300}"
HTTP_PORT="${HTTP_PORT:-9090}"
METRIC_FILE="/node-exporter/container-security.prom"
CACHE_FILE="/tmp/image-metrics.json"
TMP_METRIC_FILE="/tmp/container-security.prom.tmp"
METRICS_CACHE="/tmp/latest_metrics.prom"
CSV_CACHE="/tmp/latest_metrics.csv"
INDEX_FILE="/tmp/cg-base-index.txt"
MAX_AGE_HOURS="${MAX_AGE_HOURS:-24}"
OUTPUT_FILE="${1:-/data/adoption.csv}"  # Allow path as argument, default to /data/adoption.csv
CLUSTER_NAME="${CLUSTER_NAME:-default_cluster}" # Cluster label for metrics (default: "default_cluster")
[ -z "$CLUSTER_NAME" ] && CLUSTER_NAME="default_cluster"
HOSTNODE_NAME="${HOSTNODE_NAME:-unknown}"
CHAINCTL_IDENTITY=${CHAINCTL_IDENTITY:-unknown}
CHAINCTL_IDENTITY_PATH=${CHAINCTL_IDENTITY_PATH:-/var/run/chainguard/oidc/oidc-token}

# Mode detection
MODE_COUNT=0
[ "${WRITE_CSV:-}" = "TRUE" ] && MODE="CSV" && MODE_COUNT=$((MODE_COUNT+1))
[ "${OPENMETRICS:-}" = "TRUE" ] && MODE="OPENMETRICS" && MODE_COUNT=$((MODE_COUNT+1))
[ -z "${MODE:-}" ] && MODE="DEFAULT"
if [ "$MODE_COUNT" -gt 1 ]; then
  echo "ERROR: Only one mode (WRITE_CSV or OPENMETRICS) can be active at a time." >&2
  exit 1
fi

# Debug logging
info() { echo "$@" >&2; }
if [ "${DEBUG:-}" = "TRUE" ]; then
  set -x
  info "DEBUG MODE ENABLED"
fi

info "Using cluster label: $CLUSTER_NAME"

# Wait for token to be available (robust check)
for i in {1..10}; do
  if [ -s "$CHAINCTL_IDENTITY_PATH" ]; then
    break
  fi
  echo "Waiting for OIDC token to be mounted at $CHAINCTL_IDENTITY_PATH..."
  sleep 1
done

# Final check in case token never appeared
if [ ! -s "$CHAINCTL_IDENTITY_PATH" ]; then
  echo "OIDC token file not found or empty at $CHAINCTL_IDENTITY_PATH!"
  exit 1
fi

# chainctl login
chainctl_login() {
  login_success=0
  for i in {1..5}; do
    if chainctl auth login --identity "$CHAINCTL_IDENTITY" --identity-token "$(cat $CHAINCTL_IDENTITY_PATH)"; then
      login_success=1
      break
    fi
    echo "Retrying chainctl login ($i)..."
    sleep 2
  done

  if [ "$login_success" -ne 1 ]; then
    echo "chainctl login failed after retries!"
    exit 1
  fi

  # Only configure Docker auth if login was successful
  if [ "$login_success" -eq 1 ]; then
    chainctl auth configure-docker \
      --identity "$CHAINCTL_IDENTITY" \
      --identity-token "$(cat $CHAINCTL_IDENTITY_PATH)"
  fi
}  

# Graceful shutdown support
CLEANUP_PID=""
cleanup() {
  if [ -n "$CLEANUP_PID" ] && kill -0 "$CLEANUP_PID" 2>/dev/null; then
    kill "$CLEANUP_PID"
    wait "$CLEANUP_PID" 2>/dev/null || true
  fi
  info "Received termination signal. Exiting."
  exit 0
}
trap cleanup INT TERM

ensure_cg_index() {
  # Check if the index file exists and is fresh
  if [ -f "$INDEX_FILE" ]; then
    if [ ! -s "$INDEX_FILE" ]; then
      info "Index file exists but is empty, rebuilding..."
    else    
      AGE_HOURS=$(( ($(date +%s) - $(stat -c %Y "$INDEX_FILE")) / 3600 ))
      if [ "$AGE_HOURS" -lt "$MAX_AGE_HOURS" ]; then
        info "Using cached Chainguard base layer index (last updated $AGE_HOURS hours ago): $INDEX_FILE"
        return 0
      else
        info "Index file is stale ($AGE_HOURS hours old), rebuilding..."
      fi
    fi  
  else
    info "Index file missing, building for the first time..."
  fi

  CHAINCTL_OUTPUT=$(chainctl image list --output=terse) || { info "chainctl failed!"; exit 2; }
  if [ -z "$CHAINCTL_OUTPUT" ]; then
    info "No images returned by chainctl; skipping index build this round."
    exit 2
  fi
  > "$INDEX_FILE"  

  MAX_PROCS=8
  count=0

  info "Creating image digest cache.."
  while IFS= read -r IMAGE_LINE; do
    (
      IMAGE="${IMAGE_LINE%@sha256*}@${IMAGE_LINE##*@}"
      BASE_LAYERS=$(crane config "$IMAGE" | jq -r '.rootfs.diff_ids[]' 2>/dev/null) || {
        info "crane config failed for $IMAGE, skipping..."
        exit
      }
      for LAYER in $BASE_LAYERS; do
        echo "$LAYER $IMAGE_LINE"
      done
    ) >> "$INDEX_FILE" &
    count=$((count+1))
    if (( count >= MAX_PROCS )); then
      wait -n
      count=$((count-1))
    fi
  done <<< "$CHAINCTL_OUTPUT"

  wait

  if [ ! -s "$INDEX_FILE" ]; then
    info "ERROR: Base index build failed or is empty! Will retry next loop."
    return 3
  fi

  info "Chainguard base layer index rebuilt: $INDEX_FILE ($(wc -l < "$INDEX_FILE") lines)"
}

# Containerd socket detection
detect_containerd_socket() {
  for sock in \
    /run/containerd/containerd.sock \
    /run/k3s/containerd/containerd.sock \
    /run/k0s/containerd.sock \
    /var/run/docker.sock; do
    if [ -S "$sock" ]; then
      crictl --runtime-endpoint "unix://$sock" images >/dev/null 2>&1
      if [ $? -eq 0 ]; then
        export CONTAINER_RUNTIME_ENDPOINT="unix://$sock"
        export IMAGE_SERVICE_ENDPOINT="unix://$sock"
        info "Detected working CRI endpoint=$CONTAINER_RUNTIME_ENDPOINT"
        return 0
      fi
    fi
  done
  info "No working containerd socket found!"
  return 1
}

# Strip "unix://" and return the containerd socket path for ctr
containerd_addr() {
  echo "${CONTAINER_RUNTIME_ENDPOINT#unix://}"
}

# Use ctr to list containerd namespaces. Fallback to common ones if ctr fails.
discover_cri_namespaces() {
  local addr
  addr="$(containerd_addr)"
  if ns_list=$(ctr --address "$addr" namespaces list -q 2>/dev/null) && [ -n "$ns_list" ]; then
    echo "$ns_list"
  else
    # sensible fallbacks if ctr is unavailable or returns nothing
    echo "k8s.io moby default k3s.io k0s.io cri-containerd"
  fi
}

crictl_supports_namespace() {
  # works even on older crictl: grep for the flag in help output
  crictl images --help 2>&1 | grep -q -- '--namespace'
}

# Image metrics collector (BusyBox sh)
collect_image_metrics() {
  ARCH=$(uname -m)
  case "$ARCH" in
    x86_64) PLATFORM="linux/amd64" ;;
    aarch64) PLATFORM="linux/arm64" ;;
    *) PLATFORM="linux/amd64" ;;
  esac

  touch "$CACHE_FILE"
  [ ! -s "$CACHE_FILE" ] && echo '{}' > "$CACHE_FILE"

  CRICTL_JSON=$(crictl images -o json 2>/dev/null)
  echo "$CRICTL_JSON" | jq -e '.' >/dev/null 2>&1 || {
    info "ERROR: crictl did not return valid JSON. Aborting image scan."
    exit 2
  }
  
  NUM_IMAGES=$(echo "$CRICTL_JSON" | jq '.images | length')
  IMAGES=""
  if [ "$NUM_IMAGES" -gt 0 ]; then
    # Use BOTH repoTags and repoDigests; some images are pulled only by digest.
    IMAGES=$(echo "$CRICTL_JSON" \
      | jq -r '
          .images[]? |
          (
            (.repoTags // [])[]?,
            (.repoDigests // [])[]?
          )
        ' 2>/dev/null | awk "NF" | sort -u | tr "\n" " ")
  fi
  info "Detected $NUM_IMAGES image records; targeting $(printf '%s\n' $IMAGES | wc -w) refs (tags+digests)."  

  # === Debug: report what we saw ===
  COUNT_IMGS=$(printf '%s\n' $IMAGES | wc -w)
  info "Targeting $COUNT_IMGS image references (tags + digests)."
  if [ "${DEBUG:-}" = "TRUE" ]; then
    info "First 10 image refs:"
    printf '%s\n' $IMAGES | head -n 10 >&2
  fi  

  # Load cache
  CACHE=$(cat "$CACHE_FILE")
  PRESENT_IMAGES=""
  CHAINGUARD_IMAGES=""
  NON_CHAINGUARD_IMAGES=""
  METRICS_LINES=""

  for IMAGE in $IMAGES; do
    info "Image: $IMAGE"
    PRESENT_IMAGES="$PRESENT_IMAGES $IMAGE"
    DIGEST=$(crane digest "$IMAGE" 2>/dev/null || true)
    [ -z "$DIGEST" ] && info "Could not fetch digest for $IMAGE, skipping." && continue

    CACHED_DIGEST=$(echo "$CACHE" | jq -r --arg img "$IMAGE" '.[$img].digest // empty')
    if [ "$DIGEST" = "$CACHED_DIGEST" ]; then
      # Grab the stored lines, clean them, then append
      METRICS=$(echo "$CACHE" | jq -r --arg img "$IMAGE" '.[$img].metrics[]?' )
      if [ -n "$METRICS" ]; then
        CLEANED=$(printf '%s\n' "$METRICS" \
          | sed -e 's/^[[:space:]]*//' -e '/^$/d')
        if [ -z "$METRICS_LINES" ]; then
          METRICS_LINES="$CLEANED"
        else
          METRICS_LINES=$(printf '%s\n%s' "$METRICS_LINES" "$CLEANED")
        fi
      fi
      info "Digest unchanged, using cached metrics."

      # Extract VENDOR from cached metrics for classification
      VENDOR=$(echo "$CACHE" | jq -r --arg img "$IMAGE" '
        .[$img].metrics[]? 
        | select(startswith("node_container_image_info")) 
        | split("vendor=\"")[1]? 
        | split("\"")[0] // empty' | head -n1)
      VENDOR=${VENDOR,,}
    else
      info "Digest changed or new image, collecting metadata..."
      VENDOR=$(crane manifest "$IMAGE" 2>/dev/null | jq -r '.annotations["org.opencontainers.image.vendor"] // empty')

      if [ -z "$VENDOR" ]; then
        info "No annotation match, checking label..."
        VENDOR=$(crane config "$IMAGE" | jq -r '.config.Labels["org.opencontainers.image.vendor"] // empty')
      fi     

      VENDOR=${VENDOR,,}       

      if [[ "$VENDOR" != "chainguard" ]]; then
        info "No label match, checking layers..."
        LAYERS=$(crane config "$IMAGE" | jq -r '.rootfs.diff_ids[]')
        for LAYER in $LAYERS; do
          if grep -q "^$LAYER " "$INDEX_FILE"; then
            VENDOR="chainguard"
            break
          fi
        done
      fi

      [ -z "$VENDOR" ] && VENDOR="unknown"   

     # Robust ref parsing (handles name@sha256:... and registries with ports)
     if printf '%s' "$IMAGE" | grep -q '@sha256:'; then
       NAME="${IMAGE%@*}"
       VERSION="${IMAGE##*@}"
     else
       NAME="${IMAGE%:*}"
       VERSION="${IMAGE##*:}"
       [ "$NAME" = "$VERSION" ] && VERSION="latest"
     fi     

      info "Extracting size.."
      SIZE=$(crane manifest "$IMAGE" --platform="$PLATFORM" 2>/dev/null | jq '[.layers[].size] | add // 0' 2>/dev/null || echo 0)

      IMAGE_METRICS="node_container_image_info{image=\"$NAME\",version=\"$VERSION\",vendor=\"$VENDOR\",node=\"$HOSTNODE_NAME\",cluster=\"$CLUSTER_NAME\"} 1"
      IMAGE_METRICS="$IMAGE_METRICS
node_container_image_size_bytes{image=\"$NAME\",version=\"$VERSION\",vendor=\"$VENDOR\",node=\"$HOSTNODE_NAME\",cluster=\"$CLUSTER_NAME\"} $SIZE"

      info "Running Trivy..."
      TRIVY_OUTPUT=$(trivy image --severity CRITICAL,HIGH,MEDIUM,LOW --format json "$IMAGE" 2>/dev/null || echo "")
      if [ -n "$TRIVY_OUTPUT" ]; then
        for sev in CRITICAL HIGH MEDIUM LOW; do
          COUNT=$(echo "$TRIVY_OUTPUT" | jq "[.Results[]? | .Vulnerabilities? // [] | .[]? | select(.Severity == \"$sev\")] | length" 2>/dev/null || echo 0)
          IMAGE_METRICS="$IMAGE_METRICS
container_cve_count{image=\"$NAME\",version=\"$VERSION\",severity=\"$sev\",node=\"$HOSTNODE_NAME\",cluster=\"$CLUSTER_NAME\"} $COUNT"
        done
      fi

      # Trim leading whitespace and drop empty lines
      IMAGE_METRICS=$(printf '%s\n' "$IMAGE_METRICS" \
        | sed -e 's/^[[:space:]]*//' -e '/^$/d')

      # Append exactly one newline + the cleaned-up block into METRICS_LINES:
      if [ -z "$METRICS_LINES" ]; then
        METRICS_LINES="$IMAGE_METRICS"
      else
        METRICS_LINES=$(printf '%s\n%s' "$METRICS_LINES" "$IMAGE_METRICS")
      fi

      # Save per-image metrics in cache
      METRICS_JSON=$(echo "$IMAGE_METRICS" | jq -R . | jq -s .)
      CACHE=$(echo "$CACHE" | jq --arg img "$IMAGE" --arg dig "$DIGEST" --argjson met "$METRICS_JSON" '.[$img] = {"digest": $dig, "metrics": $met}')
    fi

    if [[ "$VENDOR" == "chainguard" ]]; then
      CHAINGUARD_IMAGES="$CHAINGUARD_IMAGES $IMAGE"
    else
      NON_CHAINGUARD_IMAGES="$NON_CHAINGUARD_IMAGES $IMAGE"
    fi
  done

  info "Removing images that no longer exist..."
  for OLD_IMAGE in $(echo "$CACHE" | jq -r 'keys[]'); do
    if ! echo " $PRESENT_IMAGES " | grep -q " $OLD_IMAGE "; then
      info "Removing cached entry for missing image: $OLD_IMAGE"
      CACHE=$(echo "$CACHE" | jq --arg img "$OLD_IMAGE" 'del(.[$img])')
    fi
  done

  info "Updating cache..."
  echo "$CACHE" > "$CACHE_FILE"

  # Export results for metrics and CSV
  export CHAINGUARD_IMAGES NON_CHAINGUARD_IMAGES IMAGES METRICS_LINES
}

generate_csv() {
  # Check that OUTPUT_FILE is set
  if [ -z "${OUTPUT_FILE:-}" ]; then
    info "ERROR: OUTPUT_FILE is not set."
    exit 10
  fi

  # Check if directory exists and is writable
  OUTPUT_DIR="$(dirname "$OUTPUT_FILE")"
  if [ ! -d "$OUTPUT_DIR" ]; then
    info "ERROR: Output directory '$OUTPUT_DIR' does not exist."
    exit 11
  fi
  if [ ! -w "$OUTPUT_DIR" ]; then
    info "ERROR: Output directory '$OUTPUT_DIR' is not writable."
    exit 12
  fi

  # Check if file exists, and if so, is writable
  if [ -e "$OUTPUT_FILE" ] && [ ! -w "$OUTPUT_FILE" ]; then
    info "ERROR: Output file '$OUTPUT_FILE' is not writable."
    exit 13
  fi

  # Collect metrics
  TOTAL=$(echo $IMAGES | wc -w)
  CG_TOTAL=$(echo $CHAINGUARD_IMAGES | wc -w)
  NON_CG_TOTAL=$(echo $NON_CHAINGUARD_IMAGES | wc -w)
  if [ "$TOTAL" -eq 0 ]; then
    PERCENT="0"
  else
    PERCENT=$(awk "BEGIN {printf \"%.1f\", ($CG_TOTAL/$TOTAL)*100}")
  fi

  # Write header if file is empty/non-existent
  if [ ! -s "$OUTPUT_FILE" ]; then
    echo "cluster_name,hostname,date,total_images,chainguard_images,non_chainguard_images,adoption_percentage" >> "$OUTPUT_FILE"
  fi

  # Append row
  echo "$CLUSTER_NAME,$HOSTNODE_NAME,$(date -Iseconds),$TOTAL,$CG_TOTAL,$NON_CG_TOTAL,$PERCENT" >> "$OUTPUT_FILE"

  # Log message on success
  info "Wrote adoption metrics row to $OUTPUT_FILE"
}

generate_metrics() {
  TMP_METRICS_FILE="${METRICS_CACHE}.tmp"
  {
    echo "# HELP node_container_image_info Container image information"
    echo "# TYPE node_container_image_info gauge"
    echo "# HELP node_container_image_size_bytes Size of images in bytes"
    echo "# TYPE node_container_image_size_bytes gauge"
    echo "# HELP container_cve_count Number of CVEs per container by severity"
    echo "# TYPE container_cve_count gauge"
    echo "$METRICS_LINES"
  } > "$TMP_METRICS_FILE"
  mv "$TMP_METRICS_FILE" "$METRICS_CACHE"
}

# Main always-on openmetrics server
main_openmetrics() {
  detect_containerd_socket || exit 3

  # Metrics collector loop in foreground in a subshell, with error handling
  (
    while true; do
      info "$(date)"

      if ! chainctl_login; then
        info "Login failed; skipping this iteration"
        sleep "$SLEEP_TIME"
        continue
      fi      

      ensure_cg_index
      collect_image_metrics
      generate_metrics
      info "Sleeping..."
      sleep "$SLEEP_TIME"
      info "---"
    done
  ) &
  CLEANUP_PID=$!

  info "Starting OpenMetrics HTTP server on port $HTTP_PORT (BusyBox mode, always-on)"
  # Serve HTTP requests forever; if metrics collector dies, exit
  while true; do
    if ! kill -0 "$CLEANUP_PID" 2>/dev/null; then
      info "Metrics collection loop died! Exiting."
      exit 1
    fi
    { echo -ne "HTTP/1.1 200 OK\r\nContent-Type: text/plain\r\n\r\n"; cat "$METRICS_CACHE"; } | nc -l -p "$HTTP_PORT" -s 0.0.0.0
  done
}

# Main CSV mode
main_csv() {
  detect_containerd_socket || exit 3
  chainctl_login
  ensure_cg_index
  collect_image_metrics
  generate_csv
}

# Main default mode
main_default() {
  detect_containerd_socket || exit 3
  while true; do
    info "$(date)"

    if ! chainctl_login; then
      info "Login failed; skipping this iteration"
      sleep "$SLEEP_TIME"
      continue
    fi
        
    ensure_cg_index
    collect_image_metrics
    generate_metrics
    TMP_METRIC_FILE="${METRIC_FILE}.tmp"
    cp "$METRICS_CACHE" "$TMP_METRIC_FILE"
    mv "$TMP_METRIC_FILE" "$METRIC_FILE"
    chmod 0644 "$METRIC_FILE"
    info "Sleeping..."
    sleep "$SLEEP_TIME"
    info "---"
  done
}

case "$MODE" in
  CSV)
    main_csv
    ;;
  OPENMETRICS)
    main_openmetrics
    ;;
  DEFAULT)
    main_default
    ;;
esac
